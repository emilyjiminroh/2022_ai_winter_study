{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "와인_분류_Checkpoint_ver_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilyjiminroh/2022_ai_winter_study/blob/main/chapter_14/%EC%99%80%EC%9D%B8_%EB%B6%84%EB%A5%98_Checkpoint_ver_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDufv2Hbb4xf",
        "outputId": "a79a4913-4185-4ead-e6a9-477cc8625300",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 데이터 입력\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "my_data = 'wine.csv'\n",
        "\n",
        "!pip install -q tensorflow-gpu==1.15.0\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy\n",
        "import os\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# seed 값 설정\n",
        "numpy.random.seed(3)\n",
        "tf.compat.v1.set_random_seed(3)\n",
        "\n",
        "# 데이터 적용\n",
        "df_pre = pd.read_csv(my_data, header=None)\n",
        "df = df_pre.sample(frac=1)\n",
        "\n",
        "dataset = df.values\n",
        "X = dataset[:,0:12]\n",
        "Y = dataset[:,12]\n",
        "\n",
        "# 모델의 설정\n",
        "model = Sequential()\n",
        "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='binary_crossentropy',\n",
        "          optimizer='adam',\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "# 모델 저장 폴더 설정\n",
        "MODEL_DIR = './model/'\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "   os.mkdir(MODEL_DIR)\n",
        "\n",
        "# 모델 저장 조건 설정\n",
        "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "# 모델 실행 및 저장\n",
        "model.fit(X, Y, validation_split=0.2, epochs=200, batch_size=200, verbose=0, callbacks=[checkpointer])\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e1e38cf7-5092-4497-9260-0684e322abb9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e1e38cf7-5092-4497-9260-0684e322abb9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving wine.csv to wine.csv\n",
            "\u001b[K     |████████████████████████████████| 411.5 MB 7.4 kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 53.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 503 kB 58.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.5 MB/s \n",
            "\u001b[?25h  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.7.0 requires tensorboard~=2.6, but you have tensorboard 1.15.0 which is incompatible.\n",
            "tensorflow 2.7.0 requires tensorflow-estimator<2.8,~=2.7.0rc0, but you have tensorflow-estimator 1.15.1 which is incompatible.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.36037, saving model to ./model/01-0.3604.hdf5\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.36037 to 0.31464, saving model to ./model/02-0.3146.hdf5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.31464 to 0.29065, saving model to ./model/03-0.2906.hdf5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.29065 to 0.27247, saving model to ./model/04-0.2725.hdf5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.27247 to 0.24940, saving model to ./model/05-0.2494.hdf5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.24940 to 0.23103, saving model to ./model/06-0.2310.hdf5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.23103 to 0.21657, saving model to ./model/07-0.2166.hdf5\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.21657 to 0.20400, saving model to ./model/08-0.2040.hdf5\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.20400 to 0.19419, saving model to ./model/09-0.1942.hdf5\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.19419 to 0.18684, saving model to ./model/10-0.1868.hdf5\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.18684 to 0.18267, saving model to ./model/11-0.1827.hdf5\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.18267\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.18267 to 0.17550, saving model to ./model/13-0.1755.hdf5\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.17550 to 0.17067, saving model to ./model/14-0.1707.hdf5\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.17067 to 0.16344, saving model to ./model/15-0.1634.hdf5\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.16344 to 0.16010, saving model to ./model/16-0.1601.hdf5\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.16010 to 0.15621, saving model to ./model/17-0.1562.hdf5\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.15621 to 0.15176, saving model to ./model/18-0.1518.hdf5\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.15176 to 0.14863, saving model to ./model/19-0.1486.hdf5\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.14863 to 0.14607, saving model to ./model/20-0.1461.hdf5\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.14607 to 0.14447, saving model to ./model/21-0.1445.hdf5\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.14447 to 0.13777, saving model to ./model/22-0.1378.hdf5\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.13777 to 0.13420, saving model to ./model/23-0.1342.hdf5\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.13420 to 0.13043, saving model to ./model/24-0.1304.hdf5\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.13043\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.13043 to 0.12331, saving model to ./model/26-0.1233.hdf5\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.12331 to 0.12075, saving model to ./model/27-0.1207.hdf5\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.12075 to 0.11602, saving model to ./model/28-0.1160.hdf5\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.11602 to 0.11275, saving model to ./model/29-0.1128.hdf5\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.11275\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.11275 to 0.10785, saving model to ./model/31-0.1079.hdf5\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.10785 to 0.10747, saving model to ./model/32-0.1075.hdf5\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.10747 to 0.10389, saving model to ./model/33-0.1039.hdf5\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.10389 to 0.10222, saving model to ./model/34-0.1022.hdf5\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.10222 to 0.10050, saving model to ./model/35-0.1005.hdf5\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.10050 to 0.10012, saving model to ./model/36-0.1001.hdf5\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.10012 to 0.09694, saving model to ./model/37-0.0969.hdf5\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.09694 to 0.09462, saving model to ./model/38-0.0946.hdf5\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.09462\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.09462\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.09462 to 0.09105, saving model to ./model/41-0.0910.hdf5\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.09105\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.09105\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.09105 to 0.09020, saving model to ./model/44-0.0902.hdf5\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.09020 to 0.08968, saving model to ./model/45-0.0897.hdf5\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.08968 to 0.08831, saving model to ./model/46-0.0883.hdf5\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.08831 to 0.08433, saving model to ./model/47-0.0843.hdf5\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.08433 to 0.08354, saving model to ./model/48-0.0835.hdf5\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.08354\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.08354\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.08354\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.08354\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.08354\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.08354\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.08354\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.08354 to 0.08021, saving model to ./model/56-0.0802.hdf5\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.08021 to 0.07740, saving model to ./model/57-0.0774.hdf5\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.07740 to 0.07610, saving model to ./model/58-0.0761.hdf5\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.07610\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.07610\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.07610 to 0.07428, saving model to ./model/61-0.0743.hdf5\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.07428\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.07428\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.07428 to 0.07182, saving model to ./model/64-0.0718.hdf5\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.07182 to 0.07132, saving model to ./model/65-0.0713.hdf5\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.07132 to 0.07059, saving model to ./model/66-0.0706.hdf5\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.07059\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.07059 to 0.07014, saving model to ./model/68-0.0701.hdf5\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.07014\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.07014 to 0.06899, saving model to ./model/70-0.0690.hdf5\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.06899\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.06899\n",
            "\n",
            "Epoch 00073: val_loss improved from 0.06899 to 0.06752, saving model to ./model/73-0.0675.hdf5\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.06752\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.06752\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.06752\n",
            "\n",
            "Epoch 00077: val_loss improved from 0.06752 to 0.06647, saving model to ./model/77-0.0665.hdf5\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.06647 to 0.06638, saving model to ./model/78-0.0664.hdf5\n",
            "\n",
            "Epoch 00079: val_loss improved from 0.06638 to 0.06600, saving model to ./model/79-0.0660.hdf5\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.06600\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.06600\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.06600\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.06600 to 0.06382, saving model to ./model/83-0.0638.hdf5\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.06382\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.06382\n",
            "\n",
            "Epoch 00086: val_loss improved from 0.06382 to 0.06335, saving model to ./model/86-0.0633.hdf5\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.06335\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.06335 to 0.06329, saving model to ./model/88-0.0633.hdf5\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.06329\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.06329\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.06329\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.06329\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.06329\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.06329 to 0.06257, saving model to ./model/94-0.0626.hdf5\n",
            "\n",
            "Epoch 00095: val_loss improved from 0.06257 to 0.05952, saving model to ./model/95-0.0595.hdf5\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.05952\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.05952\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.05952\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.05952\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.05952\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.05952\n",
            "\n",
            "Epoch 00102: val_loss improved from 0.05952 to 0.05848, saving model to ./model/102-0.0585.hdf5\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.05848\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.05848\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.05848\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.05848\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.05848\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.05848\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.05848\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.05848\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.05848\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.05848\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.05848\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.05848\n",
            "\n",
            "Epoch 00115: val_loss improved from 0.05848 to 0.05831, saving model to ./model/115-0.0583.hdf5\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.05831\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.05831\n",
            "\n",
            "Epoch 00118: val_loss improved from 0.05831 to 0.05794, saving model to ./model/118-0.0579.hdf5\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.05794\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.05794\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.05794\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.05794\n",
            "\n",
            "Epoch 00123: val_loss improved from 0.05794 to 0.05714, saving model to ./model/123-0.0571.hdf5\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.05714\n",
            "\n",
            "Epoch 00125: val_loss improved from 0.05714 to 0.05596, saving model to ./model/125-0.0560.hdf5\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.05596\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.05596\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.05596\n",
            "\n",
            "Epoch 00129: val_loss improved from 0.05596 to 0.05557, saving model to ./model/129-0.0556.hdf5\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.05557\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.05557\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.05557\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.05557\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.05557\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.05557\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.05557\n",
            "\n",
            "Epoch 00137: val_loss improved from 0.05557 to 0.05476, saving model to ./model/137-0.0548.hdf5\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.05476\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.05476\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.05476\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.05476\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.05476\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.05476\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.05476\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.05476\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.05476\n",
            "\n",
            "Epoch 00147: val_loss improved from 0.05476 to 0.05434, saving model to ./model/147-0.0543.hdf5\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.05434\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.05434\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.05434\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.05434\n",
            "\n",
            "Epoch 00152: val_loss improved from 0.05434 to 0.05379, saving model to ./model/152-0.0538.hdf5\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.05379\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.05379\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.05379\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.05379\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.05379\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.05379\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.05379\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.05379\n",
            "\n",
            "Epoch 00161: val_loss improved from 0.05379 to 0.05340, saving model to ./model/161-0.0534.hdf5\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.05340\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.05340\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.05340\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.05340\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.05340\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.05340\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.05340\n",
            "\n",
            "Epoch 00169: val_loss improved from 0.05340 to 0.05218, saving model to ./model/169-0.0522.hdf5\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.05218\n",
            "\n",
            "Epoch 00189: val_loss improved from 0.05218 to 0.05207, saving model to ./model/189-0.0521.hdf5\n",
            "\n",
            "Epoch 00190: val_loss improved from 0.05207 to 0.05200, saving model to ./model/190-0.0520.hdf5\n",
            "\n",
            "Epoch 00191: val_loss improved from 0.05200 to 0.05161, saving model to ./model/191-0.0516.hdf5\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.05161\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.05161\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.05161\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.05161\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.05161\n",
            "\n",
            "Epoch 00197: val_loss improved from 0.05161 to 0.05158, saving model to ./model/197-0.0516.hdf5\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.05158\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.05158\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.05158\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fdc7603ba90>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHOE5dawb4xl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}